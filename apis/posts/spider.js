// Generated by CoffeeScript 2.6.1
var UserAgent, axios, crypto, downloadImage, fileType, fs, options, pathLib, rssParser, uuid, writeFile;

axios = require("axios");

rssParser = require("rss-parser");

UserAgent = require("user-agents");

fs = require("fs-extra");

pathLib = require("path");

axios = require("axios");

uuid = require("uuid");

fileType = require("file-type");

crypto = require("crypto");

options = require("../../config/options");

writeFile = (path, file) => {
  return new Promise((res, rej) => {
    var writeStream;
    writeStream = new fs.createWriteStream(path);
    file.pipe(writeStream);
    writeStream.on("close", () => {
      return res();
    });
    return writeStream.on("error", (error) => {
      return rej(error);
    });
  });
};

downloadImage = async function(url, filepath) {
  var response;
  response = (await axios({
    url: url,
    method: "get",
    responseType: "stream"
  }));
  return new Promise((resolve, reject) => {
    return response.data.pipe(fs.createWriteStream(filepath)).on('error', reject).once('close', () => {
      return resolve(filepath);
    });
  });
};

module.exports = {
  feedTime: 0,
  run: async function(sendParams) {
    var auth, db, err, h, i, len, par, parser, que, req, spider_rssCycleTime, spider_rssDebug, spider_rssSwitch, t, userAgent, website, websites;
    ({db, que, par, auth, req, h} = sendParams);
    t = (await db.mysql.transaction());
    try {
      spider_rssSwitch = (await options.get("spider_rssSwitch"));
      if (!spider_rssSwitch) {
        return (await t.commit());
      }
      spider_rssDebug = (await options.get("spider_rssDebug"));
      websites = (await options.get("spider_rssSource"));
      if (!auth || (auth && auth.uid !== 1)) { //只有创建者可以拉取爬虫
        await t.commit();
        return;
      }
      spider_rssCycleTime = (await options.get("spider_rssCycleTime"));
      if (Date.now() - this.feedTime > (spider_rssCycleTime * 60 * 1000)) { //如果大于给定时间间隔
        userAgent = new UserAgent();
        parser = new rssParser({
          headers: {
            "User-Agent": userAgent.toString()
          }
        });
        this.feedTime = Date.now();
        for (i = 0, len = websites.length; i < len; i++) {
          website = websites[i];
          await (async(website) => {
            var feed, index, item, j, len1, ref, user;
            feed = (await parser.parseURL(website.url));
            //console.log feed.items[0]
            user = (await db.icat_users_extend.findOne({
              where: {
                uid: website.uid
              },
              transaction: t
            }));
            if (!user) {
              console.error(`爬虫：找不到对应uid的用户：${website.uid}`);
              return;
            }
            if (feed.items) { //翻转数据
              feed.items = feed.items.reverse();
            }
            ref = feed.items;
            for (index = j = 0, len1 = ref.length; j < len1; index = ++j) {
              item = ref[index];
              await (async(item, index) => {
                var filesTable, findFiles, img, imgs, k, l, len2, len3, len4, m, metaData, post, replaceIndex, results, skipImgs, table, upPost;
                if (spider_rssDebug && index > 1) {
                  return;
                }
                post = (await db.icat_posts.findOne({
                  where: {
                    title: "【搬运君】" + item.title
                  },
                  transaction: t
                }));
                if (!post) {
                  imgs = item.content.match(/<img src=['"]([^'"]+)['"]/g);
                  skipImgs = {};
                  imgs = (await (async function(output) {
                    var img, imgIndex, k, len2;
                    if (imgs) {
                      for (imgIndex = k = 0, len2 = imgs.length; k < len2; imgIndex = ++k) {
                        img = imgs[imgIndex];
                        await (async(img, imgIndex) => {
                          var axiosRequest, buffer, fileName, md5, ref1, ref2, stream, type, url;
                          url = /["'](.+)["']/g.exec(img)[1];
                          axiosRequest = (await axios({
                            url: url,
                            method: "get",
                            responseType: "stream",
                            headers: {
                              "User-Agent": userAgent.toString()
                            }
                          }));
                          if (!(axiosRequest && axiosRequest.data)) { //如果获取不到数据，跳过本图片
                            skipImgs[imgIndex] = true;
                            return;
                          }
                          stream = axiosRequest.data;
                          buffer = stream.readableBuffer;
                          //console.dir buffer 这里不知道为什么获取方式改了
                          type = (await fileType.fromBuffer((buffer != null ? (ref1 = buffer.head) != null ? ref1.data : void 0 : void 0) || buffer[0]));
                          //console.log type
                          fileName = uuid.v4();
                          md5 = crypto.createHash("md5").update((buffer != null ? (ref2 = buffer.head) != null ? ref2.data : void 0 : void 0) || buffer[0]).digest("hex");
                          return output.push({
                            stream: stream,
                            uid: user.uid,
                            user: website.name,
                            type: type.mime,
                            size: buffer.length,
                            isSystem: 0,
                            directory: `data/${user.homeDir}/files`,
                            path: `data/${user.homeDir}/files/${fileName}.${type.ext}`,
                            pathZip: `data/${user.homeDir}/files/${fileName}_min.${type.ext}`,
                            md5: md5,
                            name: fileName,
                            extName: type.ext,
                            defaultName: url.split("/")[url.split("/").length - 1],
                            timestamp: Date.now()
                          });
                        })(img, imgIndex);
                      }
                      return output;
                    } else {
                      return [];
                    }
                  })([]));
                  findFiles = [];
                  filesTable = [];
                  for (k = 0, len2 = imgs.length; k < len2; k++) {
                    img = imgs[k];
                    await (async(img) => {
                      var imgTable;
                      imgTable = (await db.icat_files.findOne({
                        where: {
                          md5: img.md5
                        },
                        transaction: t
                      }));
                      if (imgTable) {
                        return findFiles.push(imgTable);
                      } else {
                        return filesTable.push(img);
                      }
                    })(img);
                  }
                  //创建找不到的文件
                  filesTable = (await db.icat_files.bulkCreate(filesTable, {
                    transaction: t
                  }));

                  //写入找不到的文件
                  for (index = l = 0, len3 = filesTable.length; l < len3; index = ++l) {
                    table = filesTable[index];
                    (async(table, index) => {
                      await writeFile(pathLib.resolve(`www/${table.path}`), imgs[index].stream);
                      return (await writeFile(pathLib.resolve(`www/${table.pathZip}`), imgs[index].stream));
                    })(table, index);
                  }
                  filesTable = filesTable.concat(findFiles);
                  replaceIndex = -1;
                  item.content = item.content.replace(/<img src=['"]([^'"]+)['"]/g, (x0, x1) => {
                    replaceIndex++;
                    if (skipImgs[replaceIndex]) {
                      return `<img src='${x1}'`;
                    } else {
                      img = filesTable.find((file) => {
                        return file.md5 === imgs[replaceIndex].md5;
                      });
                      if (img) {
                        return "<img src='" + img.path + "'"; //获取真实上传路径
                      } else {
                        return `<img src='${x1}'`;
                      }
                    }
                  });
                  upPost = (await db.icat_posts.findOne({
                    where: {
                      pid: website.linkid
                    }
                  }));
                  
                  //新增爬虫原始数据
                  metaData = "<table>";
                  Object.entries(item).forEach(([key, value]) => {
                    return metaData += `<tr><th>${key}</th></tr><tr><td>${value}</td></tr>`;
                  });
                  metaData += "</table>";
                  post = (await db.icat_posts.create({
                    uid: user.uid,
                    author: website.name,
                    title: "【搬运君】" + item.title,
                    content: `${item.description ? item.description : ""}\n${item.content ? item.content : ""}\n${item["content:encoded"] ? item["content:encoded"] : ""}\n <hr> <h1>元数据</h1> ${metaData}`,
                    contentType: "spiderRss",
                    createTime: Date.now(),
                    finallyTime: Date.now(),
                    createTimestamp: Date.now(),
                    updateTimestamp: Date.now(),
                    linkid: website.linkid,
                    linkChain: upPost ? `${upPost.linkChain},${que.linkid}` : que.linkid,
                    isPrivate: 0
                  }, {
                    transaction: t
                  }));
                  results = [];
                  for (m = 0, len4 = filesTable.length; m < len4; m++) {
                    table = filesTable[m];
                    results.push((await (async(table) => {
                      return (await post.addIcat_files(table, {
                        through: {
                          whoUse: "files_posts",
                          name: "附件售价",
                          key: "fee",
                          value: 0,
                          type: "number"
                        },
                        transaction: t
                      }));
                    })(table)));
                  }
                  return results;
                }
              })(item, index);
            }
            return this.feedTime = Date.now();
          })(website);
        }
      }
      return (await t.commit());
    } catch (error1) {
      err = error1;
      console.log(err);
      return (await t.rollback());
    }
  }
};

/*
await req.server.inject
  url:"/api/posts/set"
  method:"post"
  payload:
    title:item.title
    content:item.content
    contentType:"spider-rss"
    linkid:0
    files:[]
  auth:
    strategy:"session"
    credentials:{
      userDir:(tmp = 10**10 + user.uid*1 + "").slice(1,tmp.length).match(/../g).join("/")
      user.dataValues...
    }
*/
